---
alwaysApply: true
---

# TESTING — Stratégie et Plan de Tests pour Linkart

> Version: v2.0
> But : définir la stratégie de tests complète pour garantir qualité, sécurité et stabilité de Linkart (MVP).
> 
> **Architecture v2.0**: Séparation claire entre Products (beats/kits payants) et Services (professionnels gratuits) avec système multi-pricing pour les deux. Ajout du Design System v2.0, système de favoris et playlists éditoriales.

---

## 1. Objectifs des tests

* Garantir que les features critiques (upload, paiement, escrow, téléchargement) fonctionnent.
* Empêcher les régressions via CI.
* Vérifier la sécurité et la conformité (RLS, webhooks).
* Mesurer la performance (concurrence, latence).
* Permettre à l’IA de produire code fiable et auto-testé.

---

## 2. Pyramide de tests (priorité)

1. **Unit tests** (Jest) — logique pure, hooks, helpers.
2. **Integration tests** (Supertest / Supabase test) — Edge Functions ↔ DB ↔ R2 mocks.
3. **End-to-End (E2E)** (Playwright / Detox / Expo) — parcours utilisateur complets.
4. **Load tests** (k6) — montée en charge des endpoints critiques.
5. **Security tests** — vérifications RLS, webhooks sign, input validation.

---

## 3. Outils recommandés

* Unit / Integration : **Jest** + **ts-jest** + **testing-library/react-native**
* API integration : **Supertest** (Node) ou tests via Supabase client en Node/Deno
* E2E mobile : **Playwright (web admin)** + **Expo E2E** ou **Detox** pour mobile natif
* Load testing : **k6** (scénarios JS)
* Security static : **npm audit**, **snyk** (optionnel)
* Contract tests : **Pact** (optionnel) pour webhooks paiement
* Mocking payments & R2 : **nock** (Node) / fixtures (local) / test doubles

---

## 4. Environnements de test

* **local-dev** : `supabase start` + Expo (dev) + mocked R2 (local file or MinIO)
* **ci** : ephemeral test DB (Supabase project staging) + CI secrets read-only for test webhooks (use sandbox mode)
* **staging** : intégration complète (Wave sandbox)

> Important : ne jamais exécuter tests destructifs sur prod.

---

## 5. Données de test & fixtures

* Jeu de fixtures minimal :

  * 3 users : buyer, seller, admin (OTP mocked)
  * 5 products (beat, sample, service) with preview keys pointing to small audio samples
  * 3 transactions : pending, paid_held, released
  * 2 boosts active/expired
* Stocker fixtures SQL dans `supabase/seed.test.sql`.
* Scripts helpers : `scripts/reset-test-db.sh` qui restaure un snapshot propre avant suite CI.

---

## 6. Mocks & doubles

* **Payments**: mock Wave/OM webhooks and API using `nock` or local stub server; include HMAC signature check.
* **Cloudflare R2**: either use local MinIO or mock presigned URL generation (test the logic that uses presigned URL; for upload flow, assert the function generates URL and that client PUT is done to that URL — actual storage can be stubbed).
* **Supabase**: use test project or Supabase's local emulate; ensure RLS policies active in integration tests.
* **Time**: use fake timers for expiry flows (jest.useFakeTimers) to simulate TTL expirations or escrow timeouts.

---

## 7. Test types & exemples de cas

### 7.1 Unit tests (Jest)

* Test helpers : calcul commission (5%), génération filename R2, validation licence.
* Test hooks : `useWallet` store logic (ajout / retrait / erreurs).
* Coverage threshold : **>= 80%** pour modules critiques.

Exemple test:

```ts
test('calculateCommission returns 5% and net amount', () => {
  const { commission, net } = calculateCommission(20000);
  expect(commission).toBe(1000);
  expect(net).toBe(19000);
});
```

### 7.2 Integration tests (Edge Functions + DB)

* `/api/upload-request` :

  * require `can_sell` capability → 403 sinon
  * returns presigned PUT URL + key (assert key pattern)
* `/api/upload-complete` :

  * verifies object exists (simulate HEAD) → creates product status=pending
* `/api/pay` + webhook simulation :

  * transaction created pending
  * simulate webhook signed → transaction.status = paid_held, platform_earnings created, contract URL set
* `/api/generate-download` :

  * buyer only, status paid_held or released → returns presigned GET

### 7.3 E2E tests (flows)

* Flow complet : signup -> activate seller -> upload preview -> admin approve -> buyer checkout -> payment webhook -> download file -> rating post-purchase
* Edge cases : attempt download without payment (403), preview playback works offline (caching), boost purchase affects ordering on product listing.

### 7.4 Load tests (k6)

* Scénarios ciblés :

  * `/api/generate-download` : 500 concurrent users requesting download tokens (mesurer latence, CPU, DB locks)
  * `/api/products` : simuler 200 RPS lecture listing
* KPIs acceptés : p95 latency < 800ms, no 5xx under target load.

### 7.5 Security tests

* RLS tests : user A cannot insert product for user B (use Supabase auth context)
* Webhook signature: reject invalid signature (403)
* SQL-injection simulation via malicious inputs (assert prepared queries or parameterized usage)
* Pen-test checklist (manual): retrieve sensitive env vars, try to access direct R2 object w/o token.

---

## 8. Tests pour l’escrow (modèle held)

* Scénarios :

  * paiement success -> status `paid_held` (buyer gets download, seller not credited)
  * release action (admin or auto after X days) -> status `released`, net added to seller wallet, commission recorded
  * dispute : admin sets `disputed` -> funds locked, buyer refund possible
* Vérifier que commission est calculée et enregistrée au moment de `released` (et non à `paid_held`).

---

## 9. Tests Multi-Pricing

### 9.1 Tests Produits (Beats/Kits)

**Tests de validation pricing :**
* Vérifier que `pricing_id` existe dans `product_pricing`
* Vérifier que `is_available = true` pour la licence
* Vérifier que le prix payé correspond exactement au prix de la licence
* Vérifier que `license_type` est valide (basic, non_exclusive, exclusive, lease)

**Tests de transaction avec pricing :**
```typescript
describe('Multi-pricing transactions', () => {
  it('should create transaction with valid pricing_id', async () => {
    const product = await createTestProduct();
    const pricing = await createTestPricing(product.id, 'basic', 25000);
    
    const response = await fetch('/api/pay', {
      method: 'POST',
      headers: { Authorization: `Bearer ${buyerToken}` },
      body: JSON.stringify({
        productId: product.id,
        pricingId: pricing.id,
        paymentMethod: 'wave',
        phoneNumber: '+221701234567'
      })
    });
    
    expect(response.status).toBe(200);
    const data = await response.json();
    expect(data.data.amount).toBe(25000);
  });
  
  it('should reject invalid pricing_id', async () => {
    const response = await fetch('/api/pay', {
      method: 'POST',
      headers: { Authorization: `Bearer ${buyerToken}` },
      body: JSON.stringify({
        productId: 'valid-product-id',
        pricingId: 'invalid-pricing-id',
        paymentMethod: 'wave',
        phoneNumber: '+221701234567'
      })
    });
    
    expect(response.status).toBe(400);
  });
});
```

### 9.2 Tests Services (Multi-Tiers)

**Tests de réservation avec tiers :**
* Vérifier que `pricing_tier_id` existe dans `service_pricing`
* Vérifier que le tier est disponible
* Vérifier la création de réservation avec tier sélectionné
* Vérifier la négociation de prix pour services "à la demande"

**Tests de messagerie conditionnelle :**
* Vérifier que le chat n'est activé qu'après confirmation de réservation
* Vérifier que seuls les participants de la réservation peuvent chatter
* Vérifier le blocage des tentatives de chat pour beats/kits

```typescript
describe('Service booking with multi-tiers', () => {
  it('should create booking with selected tier', async () => {
    const service = await createTestService();
    const tier = await createTestServicePricing(service.id, 'Basic Mix', 20000);
    
    const response = await fetch('/api/bookings/create', {
      method: 'POST',
      headers: { Authorization: `Bearer ${clientToken}` },
      body: JSON.stringify({
        serviceId: service.id,
        pricingTierId: tier.id,
        scheduledAt: '2025-11-15T14:00:00Z',
        notes: 'Session de mixage'
      })
    });
    
    expect(response.status).toBe(201);
    const data = await response.json();
    expect(data.data.status).toBe('pending');
  });
  
  it('should activate chat after booking confirmation', async () => {
    const booking = await createTestBooking('confirmed');
    
    const response = await fetch('/api/conversations/create', {
      method: 'POST',
      headers: { Authorization: `Bearer ${clientToken}` },
      body: JSON.stringify({
        bookingId: booking.id
      })
    });
    
    expect(response.status).toBe(201);
  });
});
```

### 9.3 Tests de Séparation Products/Services

**Tests de blocage des achats de services :**
* Vérifier que `/api/pay` rejette les tentatives d'achat de services
* Vérifier que les services ne peuvent pas être achetés via l'endpoint de paiement
* Vérifier que les services utilisent uniquement le système de réservation

```typescript
describe('Product/Service separation', () => {
  it('should reject service purchase via /api/pay', async () => {
    const service = await createTestService();
    
    const response = await fetch('/api/pay', {
      method: 'POST',
      headers: { Authorization: `Bearer ${buyerToken}` },
      body: JSON.stringify({
        productId: service.id, // Service ID
        pricingId: 'any-pricing-id',
        paymentMethod: 'wave',
        phoneNumber: '+221701234567'
      })
    });
    
    expect(response.status).toBe(400);
    const data = await response.json();
    expect(data.error.code).toBe('SERVICE_NOT_PURCHASABLE');
  });
});
```

### 9.4 Tests Favorites System (Design System v2.0)

**Tests de toggle favorite :**
* Vérifier que l'utilisateur peut liker/unliker un produit
* Vérifier l'interface optimiste (HeartIcon change immédiatement)
* Vérifier le rollback en cas d'erreur
* Vérifier la contrainte unique (user_id, product_id)

**Tests de synchronisation :**
* Vérifier la synchronisation temps réel entre devices
* Vérifier la pagination des favoris
* Vérifier l'inclusion des détails produits et pricing

```typescript
describe('Favorites System', () => {
  it('should toggle favorite with optimistic UI', async () => {
    const product = await createTestProduct();
    
    // Test optimistic UI
    const heartIcon = screen.getByTestId('heart-icon');
    expect(heartIcon).toHaveStyle({ color: 'outline' });
    
    fireEvent.press(heartIcon);
    
    // Should change immediately (optimistic)
    expect(heartIcon).toHaveStyle({ color: 'filled' });
    
    // API call should succeed
    const response = await fetch('/api/favorites', {
      method: 'POST',
      headers: { Authorization: `Bearer ${userToken}` },
      body: JSON.stringify({ productId: product.id })
    });
    
    expect(response.status).toBe(200);
    const data = await response.json();
    expect(data.data.is_favorite).toBe(true);
  });
  
  it('should rollback on error', async () => {
    const product = await createTestProduct();
    
    // Mock API failure
    fetchMock.mockRejectOnce(new Error('Network error'));
    
    const heartIcon = screen.getByTestId('heart-icon');
    fireEvent.press(heartIcon);
    
    // Should rollback to previous state
    await waitFor(() => {
      expect(heartIcon).toHaveStyle({ color: 'outline' });
    });
    
    // Should show error toast
    expect(screen.getByText('Erreur lors de la sauvegarde')).toBeInTheDocument();
  });
});
```

### 9.5 Tests Playlists System (Design System v2.0)

**Tests admin (création playlists) :**
* Vérifier que seuls les admins peuvent créer des playlists
* Vérifier la création avec métadonnées (typebeat, ambiance, BPM)
* Vérifier l'ajout/suppression de beats dans les playlists
* Vérifier l'ordre des beats (display_order)

**Tests user (consommation playlists) :**
* Vérifier que les utilisateurs voient seulement les playlists publiées
* Vérifier la lecture continue automatique
* Vérifier les contrôles du player (play/pause, next/previous)
* Vérifier l'intégration avec le système de favoris

```typescript
describe('Playlists System', () => {
  it('should allow admin to create playlist', async () => {
    const adminToken = await createAdminToken();
    
    const response = await fetch('/api/admin/playlists', {
      method: 'POST',
      headers: { Authorization: `Bearer ${adminToken}` },
      body: JSON.stringify({
        title: 'Trap Hits 2025',
        description: 'Les meilleurs trap beats',
        typebeat: 'Trap',
        ambiance: 'Énergique',
        bpm_range: '140-160'
      })
    });
    
    expect(response.status).toBe(201);
    const data = await response.json();
    expect(data.data.title).toBe('Trap Hits 2025');
    expect(data.data.is_published).toBe(false);
  });
  
  it('should reject non-admin playlist creation', async () => {
    const userToken = await createUserToken();
    
    const response = await fetch('/api/admin/playlists', {
      method: 'POST',
      headers: { Authorization: `Bearer ${userToken}` },
      body: JSON.stringify({
        title: 'My Playlist',
        description: 'Test'
      })
    });
    
    expect(response.status).toBe(403);
  });
  
  it('should allow users to consume published playlists', async () => {
    const playlist = await createTestPlaylist({ is_published: true });
    await addBeatsToPlaylist(playlist.id, [beat1, beat2, beat3]);
    
    const response = await fetch('/api/playlists');
    expect(response.status).toBe(200);
    
    const data = await response.json();
    expect(data.data).toHaveLength(1);
    expect(data.data[0].title).toBe(playlist.title);
    expect(data.data[0].beat_count).toBe(3);
  });
});
```

### 9.6 Tests Design System Components

**Tests des nouveaux composants :**
* Vérifier HeartIcon (outline/filled states, animation)
* Vérifier PlayButton (play/pause states, loading)
* Vérifier PlaylistCard (affichage métadonnées, navigation)
* Vérifier MiniPlayer (intégration HeartIcon, contrôles)

```typescript
describe('Design System Components', () => {
  it('should render HeartIcon with correct states', () => {
    const { rerender } = render(<HeartIcon isFavorite={false} onToggle={jest.fn()} />);
    expect(screen.getByTestId('heart-icon')).toHaveStyle({ color: 'outline' });
    
    rerender(<HeartIcon isFavorite={true} onToggle={jest.fn()} />);
    expect(screen.getByTestId('heart-icon')).toHaveStyle({ color: 'filled' });
  });
  
  it('should render PlaylistCard with metadata', () => {
    const playlist = {
      id: '1',
      title: 'Trap Hits',
      typebeat: 'Trap',
      ambiance: 'Énergique',
      beat_count: 15
    };
    
    render(<PlaylistCard playlist={playlist} onPress={jest.fn()} />);
    
    expect(screen.getByText('Trap Hits')).toBeInTheDocument();
    expect(screen.getByText('Trap • Énergique')).toBeInTheDocument();
    expect(screen.getByText('15 beats')).toBeInTheDocument();
  });
});
```

---

## 10. Test automation & CI pipeline

CI job (GitHub Actions) example stages:

1. checkout
2. install deps
3. `npm run lint`
4. `npm run test:unit` (jest) — fail if coverage below threshold
5. `supabase db push --project-ref $TEST_REF` (optional protected) or use test DB snapshot
6. `npm run test:integration` — spin supabase functions serve or call staging functions
7. `npm run e2e` (tagged: run on nightly or PR for main features)
8. `npm run loadtest` (scheduled, not per PR)
9. `supabase gen types typescript --local > src/types/supabase.ts` and assert no diff (CI step ensures types up-to-date)

> CI must fail if:
>
> * Unit tests fail or coverage < threshold
> * Integration tests fail
> * Types regenerated but not committed

---

## 10. Test data cleanup & isolation

* Each test suite must run in transaction or create isolated resources (unique user ids, product ids).
* After run, cleanup DB rows created (or reset DB snapshot).
* For parallel CI jobs, use per-run test schema/namespace or ephemeral Supabase project.

---

## 11. Test naming & structure

* Unit tests under `__tests__/unit/`
* Integration tests under `__tests__/integration/` with `setupTestDB()` helper
* E2E under `e2e/` with Playwright configs
* Load tests under `load/` (k6 scripts)

---

## 12. Test reporting & observability

* Collect coverage reports (lcov) and upload to Codecov or artifact.
* Export CI test reports (JUnit XML) for visibility.
* For E2E failures, capture screenshots and logs (Playwright).
* Store k6 result JSON and aggregate metrics (p95/p99).

---

## 13. How Cursor / AI must handle tests

* For any code change, Cursor must generate corresponding tests (unit + integration minimal).
* Cursor must run unit tests locally (in its dev environment) before creating PR.
* If CI fails, Cursor must:

  * fetch logs,
  * classify error (lint/test/type/security),
  * update code and tests,
  * re-run locally and iterate.
* Cursor must never produce PRs that reduce coverage or skip tests without human approval.

---

## 14. Test checklist before merge (PR template)

* [ ] Unit tests added for new logic
* [ ] Integration tests for new Edge Functions / DB changes
* [ ] **Multi-pricing tests for products (beats/kits)**
* [ ] **Multi-tier tests for services**
* [ ] **Product/Service separation tests**
* [ ] **Favorites system tests (toggle, sync, rollback)**
* [ ] **Playlists system tests (admin CRUD, user consumption)**
* [ ] **Design System components tests**
* [ ] Tests pass locally and in CI
* [ ] Types regenerated and committed (if migration)
* [ ] Lint & Prettier passed
* [ ] Security checks (webhook signatures, RLS) included
* [ ] **Pricing validation tests included**
* [ ] **Booking system tests included**
* [ ] **Messaging restrictions tests included**
* [ ] Manual QA steps included for payment-related changes

---

## 15. Sample commands (scripts)

```bash
# unit tests
npm run test:unit

# integration (requires test DB or supabase serve)
npm run test:integration

# e2e (Playwright)
npm run test:e2e

# run k6 load test
k6 run load/k6_downloads.js

# regenerate types
supabase gen types typescript --local > src/types/supabase.ts
```

---

## 16. Coverage targets

* Unit + integration combined: **>= 80%** on critical modules (payments, uploads, auth, **pricing**, **bookings**, **favorites**, **playlists**).
* **Multi-pricing tests: >= 90%** coverage for pricing validation logic.
* **Service booking tests: >= 85%** coverage for booking flow.
* **Product/Service separation tests: 100%** coverage for critical separation logic.
* **Favorites system tests: >= 90%** coverage for toggle and sync logic.
* **Playlists system tests: >= 85%** coverage for admin CRUD and user consumption.
* **Design System components tests: >= 80%** coverage for new components.
* Global project target: **>= 70%**.

---

## 17. Test ownership & cadence

* Every PR touches tests.
* **Multi-pricing tests: Required for any pricing-related changes.**
* **Service booking tests: Required for any booking/messaging changes.**
* **Product/Service separation tests: Required for any changes affecting the separation.**
* **Favorites system tests: Required for any changes to favorites functionality.**
* **Playlists system tests: Required for any changes to playlists functionality.**
* **Design System tests: Required for any new component creation or modification.**
* Nightly: run full E2E + load tests in staging.
* Weekly: security test sweep (vulnerabilities, RLS drift, **pricing validation**, **favorites sync**, **playlists permissions**).
* Monthly: test plan review, update fixtures and thresholds, **review multi-pricing test coverage**, **review favorites/playlists test coverage**.

---

## 18. Recovery & flakiness

* Mark flaky tests with `@flaky` tag and exclude from gating pipeline until stabilized.
* Maintain a **flaky tests dashboard** listing flaky tests and owners.
* Investigate failing tests within 24h.

---

## 19. Documentation & dev-experience

* `README_TESTING.md` with run instructions, env variables needed for test runs and how to start local supabase & functions.
* Provide Postman collections or curl examples for integration testing payment webhooks.
* **Multi-pricing test examples** in documentation.
* **Service booking test scenarios** documented.
* **Product/Service separation test cases** clearly explained.

---

## 20. Exemple de cas concret de test d'intégration (pseudocode)

### 20.1 Test Multi-Pricing Produit

1. Seed DB with seller & product with multiple pricing options.
2. Buyer calls `/api/products/:id/pricing` → returns available pricing options.
3. Buyer selects specific pricing tier and calls `/api/pay` with `pricingId` → returns payment instruction + tx_id.
4. Simulate Wave webhook (signed) → call `/api/payment-callback`.
5. Assert transaction.status === 'paid_held', contract_url not null, **pricing_id matches selected tier**.
6. Buyer requests `/api/generate-download` → returns presigned GET.
7. Assert download_logs has entry after consumption.
8. Simulate admin release → transaction.status === 'released', seller.wallet increased by **net amount for selected tier**.

### 20.3 Test Favorites System

1. Seed DB with user and multiple products.
2. User calls `/api/favorites` → returns empty list initially.
3. User toggles favorite on product A → calls `/api/favorites` with `productId`.
4. Assert favorite added to DB, optimistic UI updated.
5. User calls `/api/favorites` → returns product A in favorites list.
6. User toggles favorite again → assert favorite removed from DB.
7. Test rollback: mock API failure → assert UI reverts to previous state.

### 20.4 Test Playlists System

1. Seed DB with admin user and multiple products.
2. Admin creates playlist → calls `/api/admin/playlists` with metadata.
3. Admin adds beats to playlist → calls `/api/admin/playlists/:id/items`.
4. Admin publishes playlist → updates `is_published = true`.
5. User calls `/api/playlists` → returns published playlist.
6. User opens playlist → calls `/api/playlists/:id` → returns beats in order.
7. User plays playlist → tests player integration and controls.
8. Test non-admin restriction → assert 403 for playlist creation.

